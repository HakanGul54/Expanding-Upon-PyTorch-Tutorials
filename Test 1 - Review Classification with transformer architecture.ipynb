{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisite per [pytorch](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html#prerequisites)"
      ],
      "metadata": {
        "id": "h0ztIwn1B5-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xj7uI8Nm8Mka"
      },
      "outputs": [],
      "source": [
        "!pip install -U portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the necessary libraries and set the device"
      ],
      "metadata": {
        "id": "KTwPMDSLBz4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import AmazonReviewPolarity\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfERihpk8d8U",
        "outputId": "75142ebb-6c46-4f48-dec2-07130bc53193"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = AmazonReviewPolarity(split=\"train\")"
      ],
      "metadata": {
        "id": "GI8s1siwmBah"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwSfI5-OmDal",
        "outputId": "8355cf76-6a49-4936-8055-6bf8f153b200"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = AmazonReviewPolarity(split=\"train\")\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "\n",
        "# Add <pad> to your vocabulary\n",
        "vocab.append_token(\"<pad>\")\n",
        "pad_index = vocab[\"<pad>\"]\n",
        "\n",
        "# Add <eos> to your vocabulary\n",
        "vocab.append_token(\"<eos>\")\n",
        "eos_index = vocab[\"<eos>\"]\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    # max_length = max(len(text_pipeline(entry[1])) for entry in batch)  # Find the longest sequence in the batch\n",
        "    max_length = 128\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = text_pipeline(_text)\n",
        "\n",
        "        # Padding\n",
        "        while len(processed_text) < max_length - 1:\n",
        "            processed_text.append(pad_index)\n",
        "\n",
        "        if len(processed_text) >= 128:\n",
        "            processed_text = processed_text[:127]\n",
        "\n",
        "        processed_text.append(eos_index)\n",
        "\n",
        "        # Append the processed text to text_list\n",
        "        text_list.append(processed_text)\n",
        "\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    text_list = torch.stack([torch.tensor(t, dtype=torch.int64) for t in text_list])  # Convert list of lists to a tensor\n",
        "    return label_list, text_list\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "_NT7FDmg9KA_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Embedding Bag helps with the efficiency, but it makes the words lose\n",
        "# positional importance. While it helps with the training process and removes\n",
        "# the need for padding/truncating the input, it 1-dimensionalizes the data.\n",
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n",
        "\n",
        "\n",
        "class SelfAttentionHead(nn.Module):\n",
        "    def __init__(self, input_dim, head_size):\n",
        "        super(SelfAttentionHead, self).__init__()\n",
        "        self.key = nn.Linear(input_dim, head_size, bias=False)\n",
        "        self.query = nn.Linear(input_dim, head_size, bias=False)\n",
        "        self.value = nn.Linear(input_dim, head_size, bias=False)\n",
        "\n",
        "        self.mask = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        x = q @ k.transpose(-2, -1)\n",
        "        x = x.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
        "        x = F.softmax(x, dim=-1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x @ v\n",
        "        return x\n",
        "\n",
        "        # I was missing dropout\n",
        "        # key = self.key(x)\n",
        "        # query = self.query(x)\n",
        "        # kq = key @ query.transpose(-2, -1)\n",
        "        # value = self.value(x)\n",
        "\n",
        "        # kq = F.softmax(kq, dim=-1)\n",
        "        # x = kq @ value\n",
        "        # return x\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, input_dim, head_size, num_head):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(input_dim, head_size) for _ in range(num_head)])\n",
        "        self.proj = nn.Linear(head_size * num_head, input_dim)\n",
        "        self.dropout = nn.Dropout(.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "        x = self.dropout(self.proj(x))\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, input_dim, num_head):\n",
        "        super().__init__()\n",
        "        head_size = input_dim // num_head\n",
        "        self.self_attention = MultiHeadSelfAttention(input_dim, head_size, num_head)\n",
        "        self.dense1 = nn.Linear(input_dim, 4 * input_dim)\n",
        "        self.dense2 = nn.Linear(4 * input_dim, input_dim)\n",
        "        self.dropout = nn.Dropout(.2)\n",
        "        self.ln1 = nn.LayerNorm(input_dim)\n",
        "        self.ln2 = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.self_attention(self.ln1(x))\n",
        "        x = self.ln2(x)\n",
        "        x = F.relu(self.dense1(x))\n",
        "        x = self.dropout(self.dense2(x))\n",
        "        return x\n",
        "\n",
        "class TextClassificationModelWithAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, embed_dim, num_head, num_class):\n",
        "        super(TextClassificationModelWithAttention, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim, device=device)\n",
        "        self.positional_embedding = nn.Embedding(block_size, embed_dim, device=device)\n",
        "        self.blocks = nn.Sequential(*[Block(embed_dim, num_head) for _ in range(4)])\n",
        "        self.ln = nn.LayerNorm(embed_dim)\n",
        "        self.dense = nn.Linear(embed_dim, num_class)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        B, T = x.shape\n",
        "\n",
        "        token_embed = self.token_embedding(x)\n",
        "        position_embed = self.positional_embedding(torch.arange(T, device=device))\n",
        "        x = token_embed + position_embed\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.dense(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "        loss = None\n",
        "        if y is not None:\n",
        "            loss = F.cross_entropy(x, y)\n",
        "\n",
        "        return x, loss"
      ],
      "metadata": {
        "id": "K9FZnerh9Mx8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = 2 #len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 64\n",
        "block_size = 128\n",
        "head_size = 64\n",
        "num_head = 4\n",
        "#model = TextClassificationModel(vocab_size, embed_dim, num_class)\n",
        "# vocab_size, block_size, embed_dim, num_head, num_class\n",
        "model = TextClassificationModelWithAttention(vocab_size, block_size, embed_dim, num_head, num_class).to(device)\n",
        "# model = LSTM_Cell(emsize, emsize)"
      ],
      "metadata": {
        "id": "iUEBLAyM9d8c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#old size 12567365\n",
        "print(\"Model size: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tsYCfQK9hTW",
        "outputId": "a6bad135-8833-463a-9bf2-adc35b759322"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size:  100437378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, force_limit_batch=(None, None)):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    limit_batch, count = force_limit_batch\n",
        "    if limit_batch is not None:\n",
        "        current = 0\n",
        "\n",
        "    for idx, (label, text) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        text = text.to(device)\n",
        "        label = label.to(device)\n",
        "        predicted_label, loss = model(text, label)\n",
        "        #predicted_label = torch.mean(predicted_label, dim=1)  # Shape becomes [64, 4]\n",
        "        predicted_label = predicted_label.argmax(dim=1).to(device)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        #print(predicted_label.shape, label.shape)\n",
        "        #total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_acc += (predicted_label == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "        if limit_batch is not None:\n",
        "            current += 1\n",
        "            if current >= count:\n",
        "                return\n",
        "\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text) in enumerate(dataloader):\n",
        "            label = label.to(device)\n",
        "            text = text.to(device)\n",
        "            #predicted_label = model(text)\n",
        "            logits, loss = model(text)\n",
        "            predicted_label = logits.argmax(dim=1).to(device)\n",
        "            #predicted_label = torch.mean(logits, dim=1).to(device)\n",
        "            #predicted_label = torch.mean(predicted_label, dim=1).to(device)\n",
        "            # loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "            if idx == 500:\n",
        "                break\n",
        "    return total_acc / total_count"
      ],
      "metadata": {
        "id": "M86RzvZe-UYU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10  # epoch\n",
        "LR = 3e-4  # learning rate\n",
        "BATCH_SIZE = 64  # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AmazonReviewPolarity()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "upny8XWu-YWq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_dataloader))\n",
        "\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8hnTb-gJ6Ks",
        "outputId": "13c2e832-4629-4902-d92f-bffa26691ee8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64]) torch.Size([64, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader, (True, 1000))\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(\n",
        "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "        \"valid accuracy {:8.3f} \".format(\n",
        "            epoch, time.time() - epoch_start_time, accu_val\n",
        "        )\n",
        "    )\n",
        "    print(\"-\" * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "kRrV179RJQbx",
        "outputId": "f2ac65a5-3377-4a37-ef97-8e202ea08819"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   0 |   500/53438 batches | accuracy    0.854\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   0 | time: 83.66s | valid accuracy    0.862 \n",
            "-----------------------------------------------------------\n",
            "| epoch   1 |   500/53438 batches | accuracy    0.862\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ba08edcd09eb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0maccu_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccu_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-aedfb7c61cf7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, force_limit_batch)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(predicted_label.shape, label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#total_acc += (predicted_label.argmax(1) == label).sum().item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtotal_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ag_news_label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
        "label_lookup = {0: \"Negative\", 1: \"Positive\"}\n",
        "def predict(text, text_pipeline, give_all_preds=False):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(ex_text_str)).long().unsqueeze(0).to(device)\n",
        "        output, _ = model(text)\n",
        "        if give_all_preds:\n",
        "          return output\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"I was not dissatisfied with the result.\"\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "prediction = predict(ex_text_str, text_pipeline, True)\n",
        "label = prediction.argmax(1).item()\n",
        "print(\"This is a {label} review with {confidence:.2f}% confidence.\".format(label = label_lookup[label], confidence = prediction[0][label] * 100))\n",
        "torch.set_printoptions(sci_mode=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBLkJgZ570Pu",
        "outputId": "cd6f26bb-fccd-4e4a-c5a0-5cfcf5cee516"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Negative review with 99.15% confidence.\n"
          ]
        }
      ]
    }
  ]
}
